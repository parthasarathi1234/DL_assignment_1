{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Up23WKX5nIS2",
        "ZYvMuKmKjfrJ",
        "VZdpU5sXnu0b"
      ],
      "mount_file_id": "1ECsNqilPtDFQKYYhSdFApjVx_DklrB5i",
      "authorship_tag": "ABX9TyPJ9hK8e625gEgbkfvepP7z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthasarathi1234/DL_assignment_1/blob/main/DL_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3IiiF-5w6R0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa626c3a-f648-47d2-a03a-d65c265500b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
            "(54000, 28, 28) (6000, 28, 28) (54000,) (6000,)\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "(x_train,y_train),(x_test,y_test)=fashion_mnist.load_data();\n",
        "x_train_images, x_validation_images,y_train_labels, y_validation_labels  = train_test_split(x_train,y_train,test_size = 0.1)\n",
        "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
        "print(x_train_images.shape,x_validation_images.shape,y_train_labels.shape,y_validation_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question1"
      ],
      "metadata": {
        "id": "Up23WKX5nIS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=0\n",
        "i=0\n",
        "while(n!=10):\n",
        "  if(y_train[i]==n):\n",
        "    plt.subplot(3,4,n+1)\n",
        "    plt.gray()\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(y_train[i])\n",
        "    n=n+1\n",
        "  i=i+1\n",
        "plt.show()\n",
        "wandb.log({'plt':plt})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "z7s2J_I47l-3",
        "outputId": "82026543-bf5b-46f9-aad5-8be369b78822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'wandb' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-843105363231>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'plt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2\n"
      ],
      "metadata": {
        "id": "HfWSu8Q-Cmvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### weights generation   ,   Activation functions"
      ],
      "metadata": {
        "id": "Zqk2S9SqCpPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weight(No_of_layers,neurons,weightInit):\n",
        "  weights=[]\n",
        "  bias=[]\n",
        "\n",
        "  if(weightInit=='random'):\n",
        "  # input layer\n",
        "    weights.append(0.01*np.random.randn(neurons,784))\n",
        "    bias.append(0.01*np.random.randn(neurons,1))\n",
        "\n",
        "    # Hidden layer\n",
        "    for i in range(1,No_of_layers):\n",
        "      weights.append(0.01*np.random.randn(neurons,neurons))\n",
        "      bias.append(0.01*np.random.randn(neurons,1))\n",
        "\n",
        "    # output layer\n",
        "    weights.append(0.01*np.random.randn(10,neurons))\n",
        "    bias.append(0.01*np.random.randn(10,1))\n",
        "\n",
        "  elif(weightInit=='xavier'):\n",
        "    # input layer\n",
        "    weights.append(0.01*np.random.randn(neurons,784))\n",
        "    bias.append(np.zeros((neurons,1)))\n",
        "\n",
        "    # Hidden layer\n",
        "    for i in range(1,No_of_layers):\n",
        "      weights.append(0.01*np.random.randn(neurons,neurons))\n",
        "      bias.append(np.zeros((neurons,1)))\n",
        "\n",
        "    # output layer\n",
        "    weights.append(0.01*np.random.randn(10,neurons))\n",
        "    bias.append(np.zeros((10,1)))\n",
        "\n",
        "  else:\n",
        "    weights.append(np.random.randn(neurons,784))\n",
        "    bias.append(np.random.randn(neurons,1))\n",
        "\n",
        "    # Hidden layer\n",
        "    for i in range(1,No_of_layers):\n",
        "      weights.append(np.random.randn(neurons,neurons))\n",
        "      bias.append(np.random.randn(neurons,1))\n",
        "\n",
        "    # output layer\n",
        "    weights.append(0.01*np.random.randn(10,neurons))\n",
        "    bias.append(0.01*np.random.randn(10,1))\n",
        "\n",
        "\n",
        "  return weights,bias\n",
        "\n",
        "\n",
        "\n",
        "def sigmoid(a):\n",
        "  z=np.clip(a,-500, 500)\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def tanh(a):\n",
        "  z=np.clip(a,-50,50)\n",
        "  return np.tanh(z)\n",
        "\n",
        "def softmax(a):\n",
        "  x=1e-6\n",
        "  return (np.exp(a-max(a))/(sum(np.exp(a-max(a)))+x))\n",
        "\n",
        "def tanh_derivative(z):\n",
        "  return 1-np.tanh(z)**2\n",
        "\n",
        "def relu(Z):\n",
        "    A = np.maximum(0, Z)\n",
        "    return A\n",
        "\n",
        "def relu_derivative(z):\n",
        "  return np.where(z>0,1,0)\n",
        "\n",
        "def sigmoid_derivative(z):\n",
        "    return sigmoid(z) * (1 - sigmoid(z))\n",
        "\n",
        "\n",
        "\n",
        "def  feeb_forward(x,layers,act,wei,b):\n",
        "  pre_activation=[0 for i in range(layers+1)]\n",
        "  activation=[0 for i in range(layers+1)]\n",
        "  z=x.reshape(784,1)/255.0\n",
        "  # activation.append(z)\n",
        "  # activation[0]=z\n",
        "  for i in range(layers):\n",
        "    # print(weights[i].shape,z.shape,b[i].shape)\n",
        "    if(i==0):\n",
        "      pre_activation[i]=np.matmul(wei[i],z)+b[i]\n",
        "      # =a\n",
        "    else:\n",
        "      pre_activation[i]=b[i]+np.matmul(wei[i],z)  # pre activation\n",
        "      # 243/'k'\n",
        "      # =a\n",
        "    if(act==\"sigmoid\"):\n",
        "      z=sigmoid(pre_activation[i])\n",
        "    elif(act==\"tanh\"):\n",
        "      z=tanh(pre_activation[i])\n",
        "    elif(act==\"relu\"):\n",
        "      z=relu(pre_activation[i])\n",
        "    else:\n",
        "      print(\"wrong activation function\")\n",
        "    activation[i]=z\n",
        "\n",
        "  pre_activation[layers]=b[layers]+np.matmul(wei[layers],z)\n",
        "  activation[layers]=np.copy(softmax(pre_activation[layers]))\n",
        "  return pre_activation,activation,z\n",
        "\n",
        "def back_propagation(x_t,y_train,z,H,A,layers,W,activation,loss_Fun):\n",
        "  update_x=x_t.reshape(784,1)/255.0\n",
        "  dw=[0 for i in range(layers+1)]\n",
        "  db=[0 for i in range(layers+1)]\n",
        "  y=np.zeros((10,1))\n",
        "  y[y_train]=1;\n",
        "  # loss=-np.subtract(y,z)\n",
        "\n",
        "  if(loss_Fun=='crossEntropy'):\n",
        "    loss=-(y-H[layers])\n",
        "  else:\n",
        "    loss=(H[layers]-y)*H[layers]*(1-H[layers])\n",
        "\n",
        "  for k in range(len(W)-1,0,-1):\n",
        "    # print(loss.shape,H[k].shape,z.shape,y.shape)\n",
        "    dw[k]=np.matmul(loss,(H[k-1].T))\n",
        "    # print(k,loss_dw.shape)\n",
        "    # ]=loss_dw\n",
        "    # print(k,dw[k].shape)\n",
        "\n",
        "    # loss_db=loss\n",
        "    db[k]=np.copy(loss)\n",
        "\n",
        "    loss_dh=np.matmul((W[k].T),loss)\n",
        "\n",
        "    if(activation==\"tanh\"):\n",
        "      x=tanh_derivative(A[k-1])\n",
        "    elif(activation==\"sigmoid\"):\n",
        "      x=sigmoid_derivative(A[k-1])\n",
        "    elif(activation==\"relu\"):\n",
        "      x=relu_derivative(A[k-1])\n",
        "    else:\n",
        "      print(\"wrong activation function\")\n",
        "\n",
        "    loss=np.multiply(loss_dh,x)\n",
        "  dw[0]=np.matmul(loss,update_x.T)\n",
        "  db[0]=np.copy(loss)\n",
        "  return dw,db\n",
        "\n",
        "def accuracy(theta_w,theta_b,X,Y,activationfun,layers,loss_Fun):\n",
        "  # print(\"accuracy\")\n",
        "  count=0\n",
        "  loss=0\n",
        "  # print(X.shape)\n",
        "  for train_ima,train_labe in zip(X,Y):\n",
        "    p_act, act, z = feeb_forward(train_ima, layers, activationfun, theta_w, theta_b)\n",
        "    # print(np.argmax(z),np.argmax(act[layers]),end=\",\")\n",
        "    if(np.argmax(act[layers])==train_labe):\n",
        "      count=count+1\n",
        "\n",
        "    if(loss_Fun=='crossEntropy'):\n",
        "      loss+=-np.log(act[layers])[train_labe][0]\n",
        "    else:\n",
        "      loss+=(np.argmax(act[layers]-Y.shape[0])**2)\n",
        "    loss=loss/Y.shape[0]\n",
        "    acc=(count/Y.shape[0])\n",
        "  return acc*100,loss*100\n",
        "\n",
        "def accuracy_confusion(theta_w,theta_b,X,Y,activationfun,layers,loss_Fun,predicted,original):\n",
        "  # print(\"accuracy\")\n",
        "  count=0\n",
        "  loss=0\n",
        "  # print(X.shape)\n",
        "  for train_ima,train_labe in zip(X,Y):\n",
        "    p_act, act, z = feeb_forward(train_ima, layers, activationfun, theta_w, theta_b)\n",
        "    # print(np.argmax(z),np.argmax(act[layers]),end=\",\")\n",
        "    original.append(train_labe)\n",
        "    predicted.append(np.argmax(act[layers]))\n",
        "    if(np.argmax(act[layers])==train_labe):\n",
        "      count=count+1\n",
        "\n",
        "    if(loss_Fun=='crossEntropy'):\n",
        "      loss+=-np.log(act[layers])[train_labe][0]\n",
        "    else:\n",
        "      loss+=(np.argmax(act[layers]-Y.shape[0])**2)\n",
        "    loss=loss/Y.shape[0]\n",
        "    acc=(count/Y.shape[0])\n",
        "  return acc*100,loss*100"
      ],
      "metadata": {
        "id": "Ryknymv2sSpl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### weights for different neurons in each layer"
      ],
      "metadata": {
        "id": "ZYvMuKmKjfrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # for i in range(No_of_layers):\n",
        "  #   neurons.append(int(input()))   # storing no of neurons in each layer\n",
        "\n",
        "  # weights=[]\n",
        "  # bias=[]\n",
        "\n",
        "\n",
        "  # # input layer\n",
        "  # weights.append(np.random.randn(neurons[0],784))\n",
        "  # bias.append(np.random.randn(neurons[0],1))\n",
        "\n",
        "  # # Hidden layer\n",
        "\n",
        "  # for i in range(1,No_of_layers):\n",
        "  #   weights.append(np.random.randn(neurons[i],neurons[i-1]))\n",
        "  #   bias.append(np.random.randn(neurons[i],1))\n",
        "\n",
        "  # # output layer\n",
        "  # weights.append(np.random.randn(10,neurons[No_of_layers-1]))\n",
        "  # bias.append(np.random.randn(10,1))\n",
        "  # return weights,bias\n",
        "\n",
        "  # print(len(weights))\n",
        "  # for i in range(len(weights)):\n",
        "  #   print(weights[i].shape)\n",
        "\n",
        "  # for i in range(len(weights)):\n",
        "  #   print(bias[i].shape)"
      ],
      "metadata": {
        "id": "JH1fNNhyjkzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2dm4GIbMLfba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### accuracy 2"
      ],
      "metadata": {
        "id": "dqykn9Hkcot5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracyCalc(train_image,train_label,W,B,layers,activationfun,lossFun):\n",
        "  a,h,z = feeb_forward(train_image,layers,activationfun,W,B)\n",
        "  res = np.copy(h[layers])\n",
        "  maxi = res[0]\n",
        "  label = 0\n",
        "  for i in range(1,10):\n",
        "    if(res[i] > maxi ):\n",
        "      maxi = res[i]\n",
        "      label = i\n",
        "  if(lossFun == 'entropy'):\n",
        "    # print(train_label)\n",
        "    return label , -np.log(res[train_label]+(1e-5))\n",
        "  else:\n",
        "    a_l = np.zeros((10,1))\n",
        "    a_l[train_label] = 1\n",
        "    return label, np.sum((h[n]-a_l)**2)\n",
        "\n",
        "\n",
        "\n",
        "def validationAccuracy(validation_image,validation_label,W,B,layers,activationfun,lossFun):\n",
        "  a,h,z = feeb_forward(validation_image,layers,activationfun,W,B)\n",
        "  res = np.copy(h[layers])\n",
        "  maxi = res[0]\n",
        "  label = 0\n",
        "  for i in range(1,10):\n",
        "    if(res[i] > maxi ):\n",
        "      maxi = res[i]\n",
        "      label = i\n",
        "  if(lossFun == 'entropy'):\n",
        "    return label,-np.log(res[validation_label]+(1e-5))\n",
        "  else:\n",
        "    a_l = np.zeros((10,1))\n",
        "    a_l[validation_label] = 1\n",
        "    return label, np.sum((h[n]-a_l)**2)"
      ],
      "metadata": {
        "id": "lQWmbGBTx7fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JCy3uUxP0gE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y7S-pEPl0hJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### kjkfd\n"
      ],
      "metadata": {
        "id": "Bs-Aeu3r0ia3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stochastic_gradient_descent(3,0.01,3,32,\"sigmoid\",\"random\",0,\"crossEntropy\")"
      ],
      "metadata": {
        "id": "5gB9VXZ20k23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### stochastic gradient descent"
      ],
      "metadata": {
        "id": "WmRTwjcJvdT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stochastic_gradient_descent(epochs,eta,layers,neurons,activation_fun,weightInit,weightDecay,loss_Fun):\n",
        "  W, B = weight(layers,neurons,weightInit)\n",
        "  for i in range(epochs):\n",
        "    dw=[[0 for colu in range(row)] for row in range(len(W))]\n",
        "    db=[[0 for colu in range(row)] for row in range(len(B))]\n",
        "\n",
        "    for train_ima,train_labe in zip(x_train_images,y_train_labels):\n",
        "      A,H,Z=feeb_forward(train_ima,layers,activation_fun,W,B)\n",
        "      current_dw,current_db=back_propagation(train_ima,train_labe,Z,H,A,layers,W,activation_fun,loss_Fun)\n",
        "\n",
        "      for k in range(layers+1):\n",
        "        W[k]=W[k]-eta*current_dw[k]-(weightDecay*W[k])\n",
        "        B[k]=B[k]-eta*current_db[k]\n",
        "\n",
        "    acc,loss=accuracy(W,B,x_train_images,y_train_labels,activation_fun,layers,loss_Fun)\n",
        "    v_acc,v_loss=accuracy(W,B,x_validation_images,y_validation_labels,activation_fun,layers,loss_Fun)\n",
        "    print(\"Accuracy\")\n",
        "    print(acc,loss,v_acc,v_loss)\n",
        "    wandb.log({\"Train_Accuracy\" : acc,\"Train_Loss\" : loss,\"Validation_acc\" : v_acc,\"validation_loss\" : v_loss,'epoch':i})\n",
        "\n",
        "\n",
        "def momentum_gradient_descent(epochs,eta,layers,neurons,activation_fun,batchSize,weightInit,weightDecay,loss_Fun):\n",
        "  beta=0.9\n",
        "  W,B=weight(layers,neurons,weightInit)\n",
        "  pre_v_w=[0 for i in range(layers+1)]\n",
        "  pre_v_b=[0 for i in range(layers+1)]\n",
        "\n",
        "  for i in range(epochs):\n",
        "    batch=1\n",
        "    dw=[0 for i in range(layers+1)]\n",
        "    db=[0 for i in range(layers+1)]\n",
        "    for train_ima,train_labe in zip(x_train_images,y_train_labels):\n",
        "      A,H,Z=feeb_forward(train_ima,layers,activation_fun,W,B)\n",
        "      current_dw, current_db = back_propagation(train_ima,train_labe,Z,H,A,layers,W,activation_fun,loss_Fun)\n",
        "\n",
        "      for k in range(len(W)):\n",
        "        dw[k]+=current_dw[k]\n",
        "        db[k]+=current_db[k]\n",
        "\n",
        "      if(batch%batchSize==0):\n",
        "        for k in range(len(W)):\n",
        "          v_w=beta*pre_v_w[k]+dw[k]\n",
        "          v_b=beta*pre_v_b[k]+db[k]\n",
        "\n",
        "          W[k]=W[k]-(eta*v_w) - (weightDecay * W[k])\n",
        "          B[k]=B[k]-eta*v_b\n",
        "\n",
        "          pre_v_w[k]=v_w\n",
        "          pre_v_b[k]=v_b\n",
        "\n",
        "        for xw in dw:\n",
        "          xw[:]=0\n",
        "        for xb in db:\n",
        "          xb[:]=0\n",
        "      batch+=1\n",
        "\n",
        "    acc,loss=accuracy(W,B,x_train_images,y_train_labels,activation_fun,layers,loss_Fun)\n",
        "    v_acc,v_loss=accuracy(W,B,x_validation_images,y_validation_labels,activation_fun,layers,loss_Fun)\n",
        "    print(\"Accuracy\")\n",
        "    print(acc,loss,v_acc,v_loss)\n",
        "    wandb.log({\"Train_Accuracy\" : acc,\"Train_Loss\" : loss,\"Validation_acc\" : v_acc,\"validation_loss\" : v_loss,'epoch':i})\n",
        "\n",
        "\n",
        "def nesterov_accelerated_gradient_descent(epochs,layers,neurons,eta,activation_fun,batchSize,weightInit,weightDecay,loss_Fun):\n",
        "  beta=0.9\n",
        "  W,B=weight(layers,neurons,weightInit)\n",
        "  pre_v_w=[0 for i in range(layers+1)]\n",
        "  pre_v_b=[0 for i in range(layers+1)]\n",
        "\n",
        "  v_w=[0 for i in range(layers+1)]\n",
        "  v_b=[0 for i in range(layers+1)]\n",
        "\n",
        "  for i in range(epochs):\n",
        "    batch=1\n",
        "    dw=[0 for i in range(layers+1)]\n",
        "    db=[0 for i in range(layers+1)]\n",
        "\n",
        "    for k in range(len(W)):\n",
        "      W[k] = W[k] - beta * pre_v_w[k]\n",
        "      B[k] = B[k] - beta * pre_v_b[k]\n",
        "    for train_ima,train_labe in zip(x_train_images,y_train_labels):\n",
        "      A,H,Z=feeb_forward(train_ima,layers,activation_fun,W,B)\n",
        "      current_dw,current_db=back_propagation(train_ima,train_labe,Z,H,A,layers,W,activation_fun,loss_Fun)\n",
        "\n",
        "      for k in range(len(W)):\n",
        "          dw[k]+=current_dw[k]\n",
        "          db[k]+=current_db[k]\n",
        "\n",
        "      if(batch%batchSize==0):\n",
        "        for k in range(len(W)):\n",
        "          W[k]=W[k]-eta*dw[k]-(weightDecay*W[k])\n",
        "          B[k]=B[k]-eta*db[k]\n",
        "          pre_v_w[k]=eta*dw[k]+beta*pre_v_w[k]\n",
        "          pre_v_b[k]=eta*db[k]+beta*pre_v_b[k]\n",
        "        for xw in dw:\n",
        "          xw[:]=0\n",
        "        for xb in db:\n",
        "          xb[:]=0\n",
        "      batch+=1\n",
        "    acc, loss = accuracy(W,B,x_train_images,y_train_labels,activation_fun,layers,loss_Fun)\n",
        "    v_acc, v_loss = accuracy(W,B,x_validation_images,y_validation_labels,activation_fun,layers,loss_Fun)\n",
        "    print(\"Accuracy\")\n",
        "    print(acc,loss,v_acc,v_loss)\n",
        "    wandb.log({\"Train_Accuracy\" : acc,\"Train_Loss\" : loss,\"Validation_acc\" : v_acc,\"validation_loss\" : v_loss,'epoch':i})\n",
        "\n",
        "\n",
        "\n",
        "def rms_prop(epochs,layers,neurons,eta,activation_fun,batchSize,weightInit,weightDecay,loss_Fun):\n",
        "  beta=0.5\n",
        "  W,B=weight(layers,neurons,weightInit)\n",
        "  eps=1e-4\n",
        "  v_w=[0 for i in range(layers+1)]\n",
        "  v_b=[0 for i in range(layers+1)]\n",
        "\n",
        "  for i in range(epochs):\n",
        "    batch=1\n",
        "    dw=[0 for i in range(layers+1)]\n",
        "    db=[0 for i in range(layers+1)]\n",
        "    for train_ima,train_labe in zip(x_train_images,y_train_labels):\n",
        "      A, H, Z = feeb_forward(train_ima,layers,activation_fun,W,B)\n",
        "      current_dw, current_db = back_propagation(train_ima,train_labe,Z,H,A,layers,W,activation_fun,loss_Fun)\n",
        "\n",
        "      for k in range(len(W)):\n",
        "        dw[k]=dw[k]+current_dw[k]\n",
        "        db[k]=db[k]+current_db[k]\n",
        "      if(batch%batchSize==0):\n",
        "        for k in range(len(W)):\n",
        "          v_w[k]=beta*v_w[k]+(1-beta)*pow(dw[k],2)\n",
        "          v_b[k]=beta*v_b[k]+(1-beta)*pow(db[k],2)\n",
        "          W[k]=W[k]-eta*dw[k]/(np.sqrt(v_w[k])+eps) -(weightDecay*W[k])\n",
        "          B[k]=B[k]-eta*db[k]/(np.sqrt(v_b[k])+eps)\n",
        "\n",
        "        for xw in dw:\n",
        "          xw[:]=0\n",
        "        for xb in db:\n",
        "          xb[:]=0\n",
        "      batch+=1\n",
        "\n",
        "    acc,loss=accuracy(W,B,x_train_images,y_train_labels,activation_fun,layers,loss_Fun)\n",
        "    v_acc,v_loss=accuracy(W,B,x_validation_images,y_validation_labels,activation_fun,layers,loss_Fun)\n",
        "    print(\"Accuracy\")\n",
        "    print(acc,loss,v_acc,v_loss)\n",
        "    wandb.log({\"Train_Accuracy\" : acc,\"Train_Loss\" : loss,\"Validation_acc\" : v_acc,\"validation_loss\" : v_loss,'epoch':i})\n",
        "    return W,B\n",
        "\n",
        "\n",
        "\n",
        "def adam(epochs,eta,activation_fun,layers,neurons,batchSize,weightInit,weightDecay,loss_Fun):\n",
        "  beta1=0.9\n",
        "  beta2=0.999\n",
        "  W,B=weight(layers,neurons,weightInit)\n",
        "  v_w=[np.zeros_like(w) for w in W]\n",
        "  v_b=[np.zeros_like(w) for w in B]\n",
        "  m_w=[np.zeros_like(w) for w in W]\n",
        "  m_b=[np.zeros_like(w) for w in B]\n",
        "  eps=1e-10\n",
        "  for i in range(epochs):\n",
        "    batch=1\n",
        "    dw=[np.zeros_like(w) for w in W]\n",
        "    db=[np.zeros_like(w) for w in B]\n",
        "\n",
        "    for train_ima,train_labe in zip(x_train_images,y_train_labels):\n",
        "      A,H,Z=feeb_forward(train_ima,layers,activation_fun,W,B)\n",
        "      current_dw,current_db=back_propagation(train_ima,train_labe,Z,H,A,layers,W,activation_fun,loss_Fun)\n",
        "\n",
        "      for k in range(len(W)):\n",
        "        dw[k]=dw[k]+current_dw[k]\n",
        "        db[k]=db[k]+current_db[k]\n",
        "\n",
        "      if(batch%batchSize==0):\n",
        "        for k in range(len(W)):\n",
        "          m_w[k]=beta1*m_w[k]+(1-beta1)*dw[k]\n",
        "          m_b[k]=beta1*m_b[k]+(1-beta1)*db[k]\n",
        "          v_w[k]=beta2*v_w[k]+(1-beta2)*pow(dw[k],2)\n",
        "          v_b[k]=beta2*v_b[k]+(1-beta2)*pow(db[k],2)\n",
        "\n",
        "          m_w_hat=m_w[k]/(1-pow(beta1,k+1))\n",
        "          m_b_hat=m_b[k]/(1-pow(beta1,k+1))\n",
        "          v_w_hat=v_w[k]/(1-pow(beta2,k+1))\n",
        "          v_b_hat=v_b[k]/(1-pow(beta2,k+1))\n",
        "\n",
        "          W[k]=W[k]-eta*m_w_hat/(np.sqrt(v_w_hat)+eps) - (weightDecay*W[k])\n",
        "          B[k]=B[k]-eta*m_b_hat/(np.sqrt(v_b_hat)+eps)\n",
        "        for xw in dw:\n",
        "          xw[:]=0\n",
        "        for xb in db:\n",
        "          xb[:]=0\n",
        "      batch+=1\n",
        "    acc, loss = accuracy(W,B,x_train_images,y_train_labels,activation_fun,layers,loss_Fun)\n",
        "    v_acc, v_loss = accuracy(W,B,x_validation_images,y_validation_labels,activation_fun,layers,loss_Fun)\n",
        "    print(\"Accuracy\")\n",
        "    print(acc,loss,v_acc,v_loss)\n",
        "\n",
        "    wandb.log({\"Train_Accuracy\" : acc,\"Train_Loss\" : loss,\"Validation_acc\" : v_acc,\"validation_loss\" : v_loss,'epoch':i})\n",
        "\n",
        "\n",
        "\n",
        "def nadam(eta,layers,neurons,epochs,activation_fun,batchSize,weightInit,weightDecay,loss_Fun):\n",
        "  beta1=0.9\n",
        "  beta2=0.999\n",
        "  W,B=weight(layers,neurons,weightInit)\n",
        "  v_w=[np.zeros_like(w) for w in W]\n",
        "  v_b=[np.zeros_like(w) for w in B]\n",
        "  m_w=[np.zeros_like(w) for w in W]\n",
        "  m_b=[np.zeros_like(w) for w in B]\n",
        "  eps=1e-10\n",
        "  for i in range(epochs):\n",
        "    temp=1\n",
        "    dw=[np.zeros_like(w) for w in W]\n",
        "    db=[np.zeros_like(w) for w in B]\n",
        "    for train_ima,train_labe in zip(x_train_images,y_train_labels):\n",
        "      A,H,Z=feeb_forward(train_ima,layers,activation_fun,W,B)\n",
        "      current_dw,current_db=back_propagation(train_ima,train_labe,Z,H,A,layers,W,activation_fun,loss_Fun)\n",
        "      # current_dw.reverse()\n",
        "      # current_db.reverse()\n",
        "\n",
        "      for k in range(len(W)):\n",
        "        dw[k]+=current_dw[k]\n",
        "        db[k]+=current_db[k]\n",
        "\n",
        "      if(temp%batchSize==0):\n",
        "        for k in range(len(W)):\n",
        "          m_w[k]=beta1*m_w[k]+(1-beta1)*dw[k]\n",
        "          m_b[k]=beta1*m_b[k]+(1-beta1)*db[k]\n",
        "          v_w[k]=beta2*v_w[k]+(1-beta2)*pow(dw[k],2)\n",
        "          v_b[k]=beta2*v_b[k]+(1-beta2)*pow(db[k],2)\n",
        "\n",
        "          m_w_hat=m_w[k]/(1-pow(beta1,i+1))\n",
        "          m_b_hat=m_b[k]/(1-pow(beta1,i+1))\n",
        "          v_w_hat=v_w[k]/(1-pow(beta2,i+1))\n",
        "          v_b_hat=v_b[k]/(1-pow(beta2,i+1))\n",
        "\n",
        "          W[k]=W[k]-(eta/(np.sqrt(v_w_hat+eps)))*(beta1*m_w_hat+(1-beta1)*dw[k]/(1-beta1**(k+1))) - (weightDecay*W[k])\n",
        "          B[k]=B[k]-(eta/(np.sqrt(v_b_hat+eps)))*(beta1*m_b_hat+(1-beta1)*db[k]/(1-beta1**(k+1)))\n",
        "        for xw in dw:\n",
        "          xw[:]=0\n",
        "        for xb in db:\n",
        "          xb[:]=0\n",
        "      temp+=1\n",
        "    acc,loss=accuracy(W,B,x_train_images,y_train_labels,activation_fun,layers,loss_Fun)\n",
        "    v_acc,v_loss=accuracy(W,B,x_validation_images,y_validation_labels,activation_fun,layers,loss_Fun)\n",
        "    print(\"Accuracy\")\n",
        "    print(acc,loss,v_acc,v_loss)\n",
        "    wandb.log({\"Train_Accuracy\" : acc,\"Train_Loss\" : loss,\"Validation_acc\" : v_acc,\"validation_loss\" : v_loss,'epoch':i})"
      ],
      "metadata": {
        "id": "BzvkNkOOE3XJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nesterov_accelerated_gradient_descent(3,3,32,0.01,\"tanh\",100,\"random\",0,\"crossEntropy\")"
      ],
      "metadata": {
        "id": "Zd_jyqVGBJke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rms_prop(3,3,32,0.001,\"tanh\",100,\"random\",0,\"crossEntropy\")"
      ],
      "metadata": {
        "id": "gCOXBiruIfQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam(3,0.01,\"sigmoid\",4,64,64,\"random\",0,\"crossEntropy\")"
      ],
      "metadata": {
        "id": "1Oyw4fa0Ou9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nadam(0.001,3,32,3,\"tanh\",64,\"random\",0,\"crossEntropy\")"
      ],
      "metadata": {
        "id": "LkRwpUkHX5OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###all"
      ],
      "metadata": {
        "id": "VZdpU5sXnu0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs=1\n",
        "# layers=4\n",
        "# neurons=32\n",
        "# learningRate=0.1\n",
        "# beta=0.9\n",
        "# batchSize=100\n",
        "# activationFun=\"tanh\"\n",
        "# batchSize=100\n",
        "# stochastic_gradient_descent(epochs,learningRate,layers,neurons,activationFun,\"random\")\n",
        "# momentum_gradient_descent(epochs,learningRate,layers,neurons,activationFun,batchSize,\"random\")\n",
        "# nesterov_accelerated_gradient_descent(epochs,layers,neurons,learningRate,activationFun,batchSize,\"random\")\n",
        "# rms_prop(epochs,layers,neurons,learningRate,activationFun,batchSize,\"random\")\n",
        "# adam(epochs,learningRate,activationFun,layers,neurons,batchSize,\"random\")\n",
        "# nadam(learningRate,layers,neurons,epochs,activationFun,batchSize,\"random\")"
      ],
      "metadata": {
        "id": "dgEdD0GiH7EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wandb"
      ],
      "metadata": {
        "id": "SEBjaLhp_En1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wandb\n",
        "!pip install -U wandb\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "import socket\n",
        "socket.setdefaulttimeout(30)\n",
        "wandb.login()\n",
        "wandb.init(project=\"cs23m035_DL_Assignment1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "UUx7yDgW10D9",
        "outputId": "332281e8-8dad-4960-a771-bbd0db64419d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.43.0-py2.py3-none-any.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.42 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.43.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m035\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240321_083012-soan0ub8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m035/cs23m035_DL_Assignment1/runs/soan0ub8' target=\"_blank\">icy-dragon-247</a></strong> to <a href='https://wandb.ai/cs23m035/cs23m035_DL_Assignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m035/cs23m035_DL_Assignment1' target=\"_blank\">https://wandb.ai/cs23m035/cs23m035_DL_Assignment1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m035/cs23m035_DL_Assignment1/runs/soan0ub8' target=\"_blank\">https://wandb.ai/cs23m035/cs23m035_DL_Assignment1/runs/soan0ub8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cs23m035/cs23m035_DL_Assignment1/runs/soan0ub8?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x79a96c5e24a0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### confusion matrix"
      ],
      "metadata": {
        "id": "jeieQhhKUmHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_Matrix(epochs, layers, neurons, learningRate, optimizer, batchSize, activationFun, weightInit,weightDecay,loss_Fun):\n",
        "  predicted=[]\n",
        "  original=[]\n",
        "  W,B=rms_prop(epochs,layers,neurons,learningRate,activationFun,batchSize,weightInit,weightDecay,loss_Fun)\n",
        "  acc,loss=accuracy_confusion(W,B,x_train_images,y_train_labels,activationFun,layers,loss_Fun,predicted,original)\n",
        "  confusion=confusion_matrix(original,predicted)\n",
        "  plt.figure(figsize=(10,10))\n",
        "  sn.heatmap(confusion, annot=True, fmt='d',cmap='Oranges',linewidths=2,cbar=True,linecolor='black',\n",
        "          xticklabels=['0','1','2','3','4','5','6','7','8','9'], yticklabels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "  plt.xlabel(\"PREDICTED\")\n",
        "  plt.ylabel(\"ORIGINAL\")\n",
        "  plt.title('confusion matrix')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "xt3SAruUUWTE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### conncet to wandb"
      ],
      "metadata": {
        "id": "MKMnVpa_kpLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_function(epochs, layers, neurons, learningRate, optimizer, batchSize, activationFun, weightInit,weightDecay,loss_Fun):\n",
        "    if optimizer == \"SGD\":\n",
        "        accuracy=stochastic_gradient_descent(epochs, learningRate, layers, neurons, activationFun, weightInit,weightDecay,loss_Fun)\n",
        "    elif optimizer == \"MGD\":\n",
        "        accuracy=momentum_gradient_descent(epochs, learningRate, layers, neurons, activationFun, batchSize, weightInit,weightDecay,loss_Fun)\n",
        "    elif optimizer == \"NAGD\":\n",
        "        accuracy=nesterov_accelerated_gradient_descent(epochs, layers, neurons, learningRate, activationFun, batchSize, weightInit,weightDecay,loss_Fun)\n",
        "    elif optimizer == \"RMSPROP\":\n",
        "        accuracy=rms_prop(epochs, layers, neurons, learningRate, activationFun, batchSize, weightInit,weightDecay,loss_Fun)\n",
        "    elif optimizer == \"ADAM\":\n",
        "        accuracy=adam(epochs, learningRate, activationFun, layers, neurons, batchSize, weightInit,weightDecay,loss_Fun)\n",
        "    elif optimizer == \"NADAM\":\n",
        "        accuracy=nadam(learningRate, layers, neurons, epochs, activationFun, batchSize, weightInit,weightDecay,loss_Fun)\n",
        "\n",
        "def main_fun():\n",
        "    wandb.init(project='cs23m035_DL_Assignment1')\n",
        "    params = wandb.config\n",
        "    with wandb.init(project='cs23m035_DL_Assignment1', name='optimizer_func_'+params.optimizer+'_weight_initial_'+params.weightInit+'_activation_func_'+params.activationFun) as run:\n",
        "        main_function(params.maxIterations,\n",
        "                      params.layers,\n",
        "                      params.neurons,\n",
        "                      params.learningRate,\n",
        "                      params.optimizer,\n",
        "                      params.batchSize,\n",
        "                      params.activationFun,\n",
        "                      params.weightInit,\n",
        "                      params.weightDecay,\n",
        "                      params.loss_Fun)\n",
        "\n",
        "sweep_params = {\n",
        "    'method': 'bayes',\n",
        "    'name': 'Accuracy',\n",
        "    'metric': {\n",
        "        'goal': 'maximize',\n",
        "        'name': 'Validation_acc',\n",
        "    },\n",
        "    'parameters': {\n",
        "        'maxIterations': {'values': [5,10]},\n",
        "        'layers': {'values': [3,4,5]},\n",
        "        'neurons': {'values': [32, 64,128]},\n",
        "        'learningRate': {'values': [1e-3,1e-4]},\n",
        "        'optimizer': {'values': ['SGD', 'MGD', 'NAGD', 'RMSPROP', 'ADAM', 'NADAM']},\n",
        "        'batchSize': {'values': [16, 32, 64]},\n",
        "        'activationFun': {'values': ['tanh','sigmoid','relu']},\n",
        "        'weightInit': {'values': ['random', 'xavier']},\n",
        "        'weightDecay': {'values': [0,0.0005,0.5]},\n",
        "        'loss_Fun':{'values':['crossEntropy','MSE']}\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "sweepId = wandb.sweep(sweep_params, project='cs23m035_DL_Assignment1')\n",
        "wandb.agent(sweepId, function=main_fun)\n"
      ],
      "metadata": {
        "id": "u4klfrAsNxL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}